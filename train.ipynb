{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project for IANNwTF 2022/23 \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning to colorize grayscale dog pictures with the Stanford Dog Dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 20:59:17.854682: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-22 20:59:18.217751: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-22 20:59:18.391716: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-22 20:59:19.118439: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/lotta/apps/anaconda3/envs/tf-gpu/lib/\n",
      "2023-02-22 20:59:19.118549: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/lotta/apps/anaconda3/envs/tf-gpu/lib/\n",
      "2023-02-22 20:59:19.118552: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorboard\n",
    "from PIL import Image\n",
    "import os\n",
    "from datetime import datetime\n",
    "from skimage.color import rgb2lab, rgb2gray, lab2rgb\n",
    "from skimage.io import imread, imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 20:59:20.233423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 20:59:20.274195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 20:59:20.274528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 20:59:20.279874: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-22 20:59:20.283708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 20:59:20.284028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 20:59:20.284221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 20:59:21.058236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 20:59:21.058814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 20:59:21.058882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 20:59:21.058942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22063 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "# makes images same size and fills gaps at the edges with black pixels\n",
    "\n",
    "def distortion_free_resize(image, img_size):\n",
    "    w, h = img_size\n",
    "    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n",
    "    # Check tha amount of padding needed to be done.\n",
    "    pad_height = h - tf.shape(image)[0]\n",
    "    pad_width = w - tf.shape(image)[1]\n",
    "\n",
    "    # Only necessary if you want to do same amount of padding on both sides.\n",
    "    if pad_height % 2 != 0:\n",
    "        height = pad_height // 2\n",
    "        pad_height_top = height + 1\n",
    "        pad_height_bottom = height\n",
    "    else:\n",
    "        pad_height_top = pad_height_bottom = pad_height // 2\n",
    "\n",
    "    if pad_width % 2 != 0:\n",
    "        width = pad_width // 2\n",
    "        pad_width_left = width + 1\n",
    "        pad_width_right = width\n",
    "    else:\n",
    "        pad_width_left = pad_width_right = pad_width // 2\n",
    "\n",
    "    image = tf.pad(\n",
    "        image,\n",
    "        paddings=[\n",
    "            [pad_height_top, pad_height_bottom],\n",
    "            [pad_width_left, pad_width_right],\n",
    "            [0, 0],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    #image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets():\n",
    "    # go through folders \n",
    "    # make pairs of images + breed\n",
    "    # (not needed for grayscale but might need it later)\n",
    "    # divide into test and train\n",
    "    base_path = \"data/Images\"\n",
    "    lookup_table_breeds = {}\n",
    "    train_img = []\n",
    "    train_lbl = []\n",
    "    test_img = []\n",
    "    test_lbl = []\n",
    "    for num,folder in enumerate(os.listdir(base_path)):\n",
    "        lookup_table_breeds[folder[10:]] = num\n",
    "        image_paths = os.path.join(base_path, folder)\n",
    "        for count, image_path in enumerate(os.listdir(image_paths)):\n",
    "            path = os.path.join(image_paths, image_path)\n",
    "            if 0.9 * len(list(folder)) < count:\n",
    "                # makes images same size and fills gaps at the edges with black pixels\n",
    "                image = distortion_free_resize(tf.image.decode_jpeg(tf.io.read_file(path),3), (128,128))\n",
    "                # convert into Lab color space\n",
    "                train_img.append(rgb2lab(image))\n",
    "                train_lbl.append(lookup_table_breeds[folder[10:]])\n",
    "\n",
    "            else:\n",
    "                # makes images same size and fills gaps at the edges with black pixels\n",
    "                image = distortion_free_resize(tf.image.decode_jpeg(tf.io.read_file(path),3), (128,128))\n",
    "                # convert into Lab color space\n",
    "                test_img.append(rgb2lab(image))            \n",
    "                test_lbl.append(lookup_table_breeds[folder[10:]])\n",
    "\n",
    "    train_images = tf.data.Dataset.from_tensors(train_img)\n",
    "    tf.data.Dataset.save(train_images, \"saved_datasets/train_images\")\n",
    "    print(train_images)\n",
    "    train_labels = tf.data.Dataset.from_tensors(train_lbl)\n",
    "    tf.data.Dataset.save(train_labels, \"saved_datasets/train_labels\")\n",
    "    print(train_labels)\n",
    "\n",
    "    test_images = tf.data.Dataset.from_tensors(test_img)\n",
    "    tf.data.Dataset.save(test_images, \"saved_datasets/test_images\")\n",
    "    print(test_images)\n",
    "    test_labels = tf.data.Dataset.from_tensors(test_lbl)\n",
    "    tf.data.Dataset.save(test_labels, \"saved_datasets/test_labels\")\n",
    "    print(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    train_images = tf.data.Dataset.load(\"saved_datasets/train_images\")\n",
    "    train_labels = tf.data.Dataset.load(\"saved_datasets/train_labels\")\n",
    "    test_images = tf.data.Dataset.load(\"saved_datasets/test_images\")\n",
    "    test_labels = tf.data.Dataset.load(\"saved_datasets/test_labels\")\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "datasets_stored = True\n",
    "\n",
    "if datasets_stored:\n",
    "    train_images, train_labels, test_images, test_labels = load_datasets()\n",
    "else:\n",
    "    prepare_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=((TensorSpec(shape=(None, 17997, 128, 128), dtype=tf.float32, name=None), TensorSpec(shape=(None, 17997, 128, 128, 2), dtype=tf.float32, name=None)), TensorSpec(shape=(None, 17997, 120), dtype=tf.float32, name=None))>\n",
      "<BatchDataset element_spec=((TensorSpec(shape=(None, 2583, 128, 128), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2583, 128, 128, 2), dtype=tf.float32, name=None)), TensorSpec(shape=(None, 2583, 120), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def preprocess_dataset(images, labels):\n",
    "    \n",
    "    # flip each image left-right with a chance of 0.3\n",
    "    images = images.map(lambda x: (tf.reverse(x, axis=[-2])) if random.random() < 0.3 else (x))\n",
    "\n",
    "    # divide into greyscale input and color output\n",
    "    images = images.map(lambda x: (x[:,:,:,0], x[:,:,:,1:]))\n",
    "\n",
    "    labels = labels.map(lambda x: tf.one_hot(x, 120))\n",
    "    zipped = tf.data.Dataset.zip((images, labels))\n",
    "    \n",
    "    zipped = zipped.cache().shuffle(1000).batch(batch_size)\n",
    "\n",
    "    return zipped\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = preprocess_dataset(train_images, train_labels)\n",
    "test_dataset = preprocess_dataset(test_images, test_labels)\n",
    "\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "\n",
    "# the dataset has the format\n",
    "# greyscale images (64,64), a and b terms from lab color space (64,64,2), onehotted labels (120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# or take different crops from the pictures\n",
    "\n",
    "# show sample pictures from dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "# create the whole autoencoder model\n",
    "# (steal from https://towardsdatascience.com/image-colorization-using-convolutional-autoencoders-fdabc1cb1dbe )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "# log results with tensorboard \n",
    "# save model to be able to reuse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-50ab1460c2d84358\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-50ab1460c2d84358\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be5498235a11125f8b9cbeecb800fcd2f42e8279b58f495bdc82a203ff5bcb8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
