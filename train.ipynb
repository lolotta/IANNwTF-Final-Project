{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project for IANNwTF 2022/23 \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning to colorize grayscale dog pictures with the Stanford Dog Dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorboard\n",
    "from PIL import Image\n",
    "import os\n",
    "from datetime import datetime\n",
    "from skimage.color import rgb2lab, rgb2gray, lab2rgb\n",
    "from skimage.io import imread, imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from keras.layers import Dense, Conv2D, Reshape, GlobalAveragePooling2D, MaxPooling2D, UpSampling2D, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "# makes images same size and fills gaps at the edges with black pixels\n",
    "\n",
    "def distortion_free_resize(image, img_size):\n",
    "    w, h = img_size\n",
    "    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n",
    "    # Check tha amount of padding needed to be done.\n",
    "    pad_height = h - tf.shape(image)[0]\n",
    "    pad_width = w - tf.shape(image)[1]\n",
    "\n",
    "    # Only necessary if you want to do same amount of padding on both sides.\n",
    "    if pad_height % 2 != 0:\n",
    "        height = pad_height // 2\n",
    "        pad_height_top = height + 1\n",
    "        pad_height_bottom = height\n",
    "    else:\n",
    "        pad_height_top = pad_height_bottom = pad_height // 2\n",
    "\n",
    "    if pad_width % 2 != 0:\n",
    "        width = pad_width // 2\n",
    "        pad_width_left = width + 1\n",
    "        pad_width_right = width\n",
    "    else:\n",
    "        pad_width_left = pad_width_right = pad_width // 2\n",
    "\n",
    "    image = tf.pad(\n",
    "        image,\n",
    "        paddings=[\n",
    "            [pad_height_top, pad_height_bottom],\n",
    "            [pad_width_left, pad_width_right],\n",
    "            [0, 0],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    #image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets():\n",
    "    # go through folders \n",
    "    # make pairs of images + breed\n",
    "    # (not needed for grayscale but might need it later)\n",
    "    # divide into test and train\n",
    "    base_path = \"data/Images\"\n",
    "    lookup_table_breeds = {}\n",
    "    train_img = []\n",
    "    train_lbl = []\n",
    "    test_img = []\n",
    "    test_lbl = []\n",
    "    for num,folder in enumerate(os.listdir(base_path)):\n",
    "        lookup_table_breeds[folder[10:]] = num\n",
    "        image_paths = os.path.join(base_path, folder)\n",
    "        for count, image_path in enumerate(os.listdir(image_paths)):\n",
    "            path = os.path.join(image_paths, image_path)\n",
    "            if 0.9 * len(list(folder)) < count:\n",
    "                # makes images same size and fills gaps at the edges with black pixels\n",
    "                image = distortion_free_resize(tf.image.decode_jpeg(tf.io.read_file(path),3), (128,128))\n",
    "                # convert into Lab color space\n",
    "                train_img.append(rgb2lab(image/255))\n",
    "                train_lbl.append(lookup_table_breeds[folder[10:]])\n",
    "\n",
    "            else:\n",
    "                # makes images same size and fills gaps at the edges with black pixels\n",
    "                image = distortion_free_resize(tf.image.decode_jpeg(tf.io.read_file(path),3), (128,128))\n",
    "                # convert into Lab color space\n",
    "                test_img.append(rgb2lab(image/255))            \n",
    "                test_lbl.append(lookup_table_breeds[folder[10:]])\n",
    "\n",
    "    train_images = tf.data.Dataset.from_tensor_slices(train_img)\n",
    "    tf.data.Dataset.save(train_images, \"saved_datasets/train_images\")\n",
    "    print(train_images)\n",
    "    train_labels = tf.data.Dataset.from_tensor_slices(train_lbl)\n",
    "    tf.data.Dataset.save(train_labels, \"saved_datasets/train_labels\")\n",
    "    print(train_labels)\n",
    "\n",
    "    test_images = tf.data.Dataset.from_tensor_slices(test_img)\n",
    "    tf.data.Dataset.save(test_images, \"saved_datasets/test_images\")\n",
    "    print(test_images)\n",
    "    test_labels = tf.data.Dataset.from_tensor_slices(test_lbl)\n",
    "    tf.data.Dataset.save(test_labels, \"saved_datasets/test_labels\")\n",
    "    print(test_labels)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    train_images = tf.data.Dataset.load(\"saved_datasets/train_images\")\n",
    "    train_labels = tf.data.Dataset.load(\"saved_datasets/train_labels\")\n",
    "    test_images = tf.data.Dataset.load(\"saved_datasets/test_images\")\n",
    "    test_labels = tf.data.Dataset.load(\"saved_datasets/test_labels\")\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "datasets_stored = True\n",
    "\n",
    "if datasets_stored:\n",
    "    train_images, train_labels, test_images, test_labels = load_datasets()\n",
    "else:\n",
    "    train_images, train_labels, test_images, test_labels = prepare_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=((TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 128, 128, 2), dtype=tf.float32, name=None)), TensorSpec(shape=(None, 120), dtype=tf.int16, name=None))>\n",
      "<PrefetchDataset element_spec=((TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 128, 128, 2), dtype=tf.float32, name=None)), TensorSpec(shape=(None, 120), dtype=tf.int16, name=None))>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def preprocess_dataset(images, labels):\n",
    "    \n",
    "    # flip each image left-right with a chance of 0.3\n",
    "    images = images.map(lambda x: (tf.reverse(x, axis=[-2])) if random.random() < 0.5 else (x))\n",
    "    images = images.map(lambda x: (tf.reverse(x, axis=[-3])) if random.random() < 0.5 else (x))\n",
    "\n",
    "    # divide into greyscale input and color output\n",
    "\n",
    "    images = images.map(lambda x: ((tf.expand_dims(x[:,:,0], -1))/100, (x[:,:,1:]/128)))\n",
    "    labels = labels.map(lambda x: tf.one_hot(x, 120))\n",
    "    labels = labels.map(lambda x: (tf.cast(x, tf.int16)))\n",
    "\n",
    "    zipped = tf.data.Dataset.zip((images, labels))\n",
    "    \n",
    "    zipped = zipped.cache().shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return zipped\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = preprocess_dataset(train_images, train_labels)\n",
    "test_dataset = preprocess_dataset(test_images, test_labels)\n",
    "\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "\n",
    "# the dataset has the format\n",
    "# greyscale images (64,64), a and b terms from lab color space (64,64,2), onehotted labels (120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# or take different crops from the pictures\n",
    "\n",
    "# show sample pictures from dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Low_Level_Features(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(64, 3, activation='relu', padding='same', strides=1) \n",
    "        self.conv2 = Conv2D(128, 3, activation='relu', padding='same', strides=1) \n",
    "        self.conv3 = Conv2D(128, 3, activation='relu', padding='same', strides=2) \n",
    "        self.conv4 = Conv2D(256, 3, activation='relu', padding='same', strides=1) \n",
    "        self.conv5 = Conv2D(256, 3, activation='relu', padding='same', strides=2) \n",
    "        self.conv6 = Conv2D(512, 3, activation='relu', padding='same', strides=1) \n",
    "\n",
    "    def __call__(self, x, training=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mid_Level_Features(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(512, 3, activation='relu', padding='same', strides=1) \n",
    "        self.conv2 = Conv2D(256, 3, activation='relu', padding='same', strides=1) \n",
    "\n",
    "    def __call__(self, x, training=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class High_Level_Features(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(512, 3, activation='relu', padding='same', strides=2) \n",
    "        self.conv2 = Conv2D(512, 3, activation='relu', padding='same', strides=1) \n",
    "        self.conv3 = Conv2D(512, 3, activation='relu', padding='same', strides=2) \n",
    "        self.conv4 = Conv2D(512, 3, activation='relu', padding='same', strides=1) \n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(1024, activation=\"relu\")\n",
    "        self.dense2 = Dense(512, activation=\"relu\")\n",
    "        self.dense3 = Dense(256, activation=\"relu\")\n",
    "\n",
    "    def __call__(self, x, training=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification_Network(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = Dense(256, activation=\"relu\")\n",
    "        self.dense2 = Dense(120, activation=\"softmax\")\n",
    "\n",
    "    def __call__(self, x, training=False):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fusion_Layer(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #32,256,256\n",
    "        #\n",
    "\n",
    "        self.repeat_layer = tf.keras.layers.RepeatVector(32*32)\n",
    "        self.reshape = tf.keras.layers.Reshape(([32,32,256]))\n",
    "        self.concat = tf.keras.layers.Concatenate(axis=3)\n",
    "        self.conv = Conv2D(256, kernel_size=1,strides=1, activation=\"relu\", padding=\"same\")\n",
    "\n",
    "\n",
    "    def __call__(self, mid_level, global_vector, training=False):\n",
    "        x = self.repeat_layer(global_vector) \n",
    "        x = self.reshape(x)\n",
    "        x = self.concat([mid_level, x]) \n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colorization_Network(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(128, 3, activation='relu', padding='same', strides=1) \n",
    "        self.upsampling1 = UpSampling2D(2)\n",
    "        self.conv2 = Conv2D(64, 3, activation='relu', padding='same', strides=1) \n",
    "        self.conv3 = Conv2D(64, 3, activation='relu', padding='same', strides=1)\n",
    "        self.upsampling2 = UpSampling2D(2) \n",
    "        self.conv4 = Conv2D(32, 3, activation='relu', padding='same', strides=1)\n",
    "        self.conv5 = Conv2D(2, 3, activation='relu', padding='same', strides=1) \n",
    "\n",
    "    def __call__(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.upsampling1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.upsampling2(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colorization_Model(tf.keras.Model):\n",
    "    def __init__(self, optimizer, loss_function_color, loss_function_category):\n",
    "        super().__init__()\n",
    "        self.low_level = Low_Level_Features()        \n",
    "        self.mid_level = Mid_Level_Features()\n",
    "        self.high_level = High_Level_Features()\n",
    "        self.fusion = Fusion_Layer()\n",
    "        self.colorization = Colorization_Network()\n",
    "        self.classification = Classification_Network()\n",
    "\n",
    "        self.metrics_list = [\n",
    "            tf.keras.metrics.Mean(name=\"loss_color\"),\n",
    "            tf.keras.metrics.Mean(name=\"loss_category\")]\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_function_color = loss_function_color\n",
    "        self.loss_function_category = loss_function_category\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_state()\n",
    "\n",
    "    def call(self, input, training=False):\n",
    "        low = self.low_level(input)\n",
    "        middle = self.mid_level(low)\n",
    "        high = self.high_level(low)\n",
    "        fused = self.fusion(middle, high)\n",
    "        colored = self.colorization(fused)\n",
    "        label = self.classification(high)\n",
    "        return colored, label\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        images,  label = data\n",
    "        grey_image, color_image = images\n",
    "        with tf.GradientTape() as tape: \n",
    "            predicted_color, predicted_label = self(grey_image, training = True)\n",
    "            loss_color = self.loss_function_color(color_image, predicted_color)\n",
    "            loss_category  = self.loss_function_category(label, predicted_label)\n",
    "\n",
    "        gradients = tape.gradient([loss_color, loss_category], self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients,self.trainable_variables))\n",
    "        self.metrics[0].update_state(loss_color)  \n",
    "        self.metrics[1].update_state(loss_category)  \n",
    "        return predicted_color, color_image, predicted_label\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        images, label = data\n",
    "        grey_image, color_image = images    \n",
    "        predicted_color, predicted_label = self(grey_image, training = True)\n",
    "        loss_color = self.loss_function_color(color_image, predicted_color)\n",
    "        loss_category  = self.loss_function_category(label, predicted_label)            \n",
    "        self.metrics[0].update_state(loss_color)  \n",
    "        self.metrics[1].update_state(loss_category)  \n",
    "        return predicted_color, color_image, predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder from https://arxiv.org/pdf/1712.03400.pdf\n",
    "\n",
    "# model\n",
    "\n",
    "# create the whole autoencoder model\n",
    "# (steal from https://towardsdatascience.com/image-colorization-using-convolutional-autoencoders-fdabc1cb1dbe )\n",
    "\n",
    "#encoder\n",
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    #input 1,128,128\n",
    "    self.conv1 = Conv2D(64, 3, activation='relu', padding='same', strides=1) \n",
    "    self.conv2 = Conv2D(128, 3, activation='relu', padding='same', strides=2) \n",
    "    self.conv3 = Conv2D(128, 3, activation='relu', padding='same', strides=1) \n",
    "    self.conv4 = Conv2D(256, 3, activation='relu', padding='same', strides=2) \n",
    "    self.conv5 = Conv2D(256, 3, activation='relu', padding='same', strides=1) \n",
    "    self.conv6 = Conv2D(512, 3, activation='relu', padding='same', strides=1) \n",
    "    self.conv7 = Conv2D(512, 3, activation='relu', padding='same', strides=1) \n",
    "    self.conv8 = Conv2D(256, 3, activation='relu', padding='same', strides=1) \n",
    "\n",
    "    self.flatten = Flatten()\n",
    "\n",
    "\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, x, training=False):\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.conv5(x)\n",
    "    x = self.conv6(x)\n",
    "    x = self.conv7(x)\n",
    "    x = self.conv8(x)\n",
    "    x = self.flatten(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# decoder\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reshape = Reshape((32, 32, 256))\n",
    "        \n",
    "        self.conv1 = Conv2D(256, 3, activation=\"relu\", padding=\"same\", strides=1)\n",
    "        self.conv2 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")\n",
    "        self.upsampling2 = UpSampling2D(2)\n",
    "        self.conv3 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")\n",
    "        self.conv4 = Conv2D(64, 3, activation=\"tanh\", padding=\"same\")\n",
    "        self.upsampling4 = UpSampling2D(2)\n",
    "        self.conv5 = Conv2D(32, 3, activation=\"tanh\", padding=\"same\")\n",
    "        self.conv5 = Conv2D(2, 3, activation=\"tanh\", padding=\"same\")\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x, training=False):\n",
    "        x = self.reshape(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.upsampling2(x)        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)        \n",
    "        x = self.upsampling4(x)\n",
    "        x = self.conv5(x)\n",
    "        return x\n",
    "\n",
    "class Autoencoder(tf.keras.Model):\n",
    "  def __init__(self, optimizer, loss_function):\n",
    "    super().__init__()\n",
    "    self.enc = Encoder()\n",
    "    self.dec = Decoder()\n",
    "\n",
    "    self.metrics_list = [\n",
    "      tf.keras.metrics.Mean(name=\"loss\")]\n",
    "\n",
    "    self.optimizer = optimizer\n",
    "    self.loss_function = loss_function\n",
    "\n",
    "  @property\n",
    "  def metrics(self):\n",
    "    return self.metrics_list\n",
    "  \n",
    "  def get_encoder(self):\n",
    "    return self.enc\n",
    "   \n",
    "  def get_decoder(self):\n",
    "    return self.dec\n",
    "    \n",
    "  def reset_metrics(self):\n",
    "     for metric in self.metrics:\n",
    "        metric.reset_state()\n",
    "\n",
    "  def call(self, input, training=False):\n",
    "    embedding = self.enc(input)\n",
    "    output = self.dec(embedding)\n",
    "    return output\n",
    "\n",
    "  @tf.function\n",
    "  def train_step(self, data):\n",
    "    images,  label = data\n",
    "    grey_image, color_image = images\n",
    "    with tf.GradientTape() as tape: \n",
    "      prediction = self(grey_image, training = True)\n",
    "      loss = self.loss_function(color_image, prediction)\n",
    "\n",
    "    gradients = tape.gradient(loss, self.trainable_variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients,self.trainable_variables))\n",
    "    self.metrics[0].update_state(loss)  \n",
    "    return gradients\n",
    "\n",
    "  @tf.function\n",
    "  def test_step(self, data):\n",
    "    images, label = data\n",
    "    grey_image, color_image = images    \n",
    "    prediction = self(grey_image, training = False)\n",
    "    loss = self.loss_function(color_image, prediction)\n",
    "    self.metrics[0].update_state(loss)\n",
    "    return prediction, color_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "# log results with tensorboard \n",
    "# save model to be able to reuse it\n",
    "\n",
    "def training_loop(model, train_ds, test_ds, epochs, train_summary_writer, test_summary_writer, save_path):\n",
    "    for epoch in range(epochs):\n",
    "        model.reset_metrics()\n",
    "\n",
    "        for data in tqdm(train_ds, position=0, leave=True):\n",
    "            predicted_color, color_image, predicted_label = model.train_step(data)\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar(model.metrics[0].name, model.metrics[0].result(), step=epoch)\n",
    "            tf.summary.scalar(model.metrics[1].name, model.metrics[1].result(), step=epoch)\n",
    "        \n",
    "        print(\"Epoch: \", epoch+1)\n",
    "        print(\"Loss Color: \", model.metrics[0].result().numpy(), \"(Train)\")\n",
    "        print(\"Loss Category: \", model.metrics[1].result().numpy(), \"(Train)\")\n",
    "        model.reset_metrics()\n",
    "\n",
    "        for data in tqdm(test_ds, position=0, leave=True):\n",
    "            predicted_color, color_image, predicted_label = model.test_step(data)\n",
    "\n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar(model.metrics[0].name, model.metrics[0].result(), step=epoch)\n",
    "            tf.summary.scalar(model.metrics[1].name, model.metrics[1].result(), step=epoch)\n",
    "            \n",
    "        print(\"Loss Color: \", model.metrics[0].result().numpy(), \"(Test)\")\n",
    "        print(\"Loss Category: \", model.metrics[1].result().numpy(), \"(Test)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:58<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Loss Color:  0.54163533 (Train)\n",
      "Loss Category:  4.5723143 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 15.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010273763 (Test)\n",
      "Loss Category:  6.3231587 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n",
      "Loss Color:  0.010353955 (Train)\n",
      "Loss Category:  3.5949357 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010324607 (Test)\n",
      "Loss Category:  7.631134 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n",
      "Loss Color:  0.010344787 (Train)\n",
      "Loss Category:  3.4424226 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010306317 (Test)\n",
      "Loss Category:  7.887762 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n",
      "Loss Color:  0.010351016 (Train)\n",
      "Loss Category:  3.4287958 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010272989 (Test)\n",
      "Loss Category:  7.4785013 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n",
      "Loss Color:  0.01035533 (Train)\n",
      "Loss Category:  3.9825053 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010308668 (Test)\n",
      "Loss Category:  7.914268 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6\n",
      "Loss Color:  0.01035941 (Train)\n",
      "Loss Category:  4.243603 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010360895 (Test)\n",
      "Loss Category:  5.000329 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:56<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7\n",
      "Loss Color:  0.010355298 (Train)\n",
      "Loss Category:  4.874608 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010286603 (Test)\n",
      "Loss Category:  4.7921333 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8\n",
      "Loss Color:  0.0103448145 (Train)\n",
      "Loss Category:  4.8221436 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.01029394 (Test)\n",
      "Loss Category:  4.792048 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9\n",
      "Loss Color:  0.010355698 (Train)\n",
      "Loss Category:  4.8078246 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010252784 (Test)\n",
      "Loss Category:  4.793493 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10\n",
      "Loss Color:  0.01035431 (Train)\n",
      "Loss Category:  4.8035135 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010306074 (Test)\n",
      "Loss Category:  4.794635 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11\n",
      "Loss Color:  0.010358476 (Train)\n",
      "Loss Category:  4.8013296 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010303264 (Test)\n",
      "Loss Category:  4.795979 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12\n",
      "Loss Color:  0.010350909 (Train)\n",
      "Loss Category:  4.8000064 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010290599 (Test)\n",
      "Loss Category:  4.79671 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13\n",
      "Loss Color:  0.010361777 (Train)\n",
      "Loss Category:  4.79903 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010272786 (Test)\n",
      "Loss Category:  4.798006 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14\n",
      "Loss Color:  0.010349632 (Train)\n",
      "Loss Category:  4.798098 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010297993 (Test)\n",
      "Loss Category:  4.7987585 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15\n",
      "Loss Color:  0.010362829 (Train)\n",
      "Loss Category:  4.7975836 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010295271 (Test)\n",
      "Loss Category:  4.7995033 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16\n",
      "Loss Color:  0.01038085 (Train)\n",
      "Loss Category:  4.7969637 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.0102972165 (Test)\n",
      "Loss Category:  4.800294 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17\n",
      "Loss Color:  0.01036346 (Train)\n",
      "Loss Category:  4.796361 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.01027998 (Test)\n",
      "Loss Category:  4.8011074 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18\n",
      "Loss Color:  0.01037075 (Train)\n",
      "Loss Category:  4.7957706 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010290338 (Test)\n",
      "Loss Category:  4.8023033 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19\n",
      "Loss Color:  0.010348267 (Train)\n",
      "Loss Category:  4.7953362 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010289506 (Test)\n",
      "Loss Category:  4.8024 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20\n",
      "Loss Color:  0.01036288 (Train)\n",
      "Loss Category:  4.7935505 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010326576 (Test)\n",
      "Loss Category:  4.8030353 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:56<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  21\n",
      "Loss Color:  0.010341089 (Train)\n",
      "Loss Category:  4.795476 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.01024923 (Test)\n",
      "Loss Category:  4.8028316 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  22\n",
      "Loss Color:  0.010354211 (Train)\n",
      "Loss Category:  4.790419 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010289359 (Test)\n",
      "Loss Category:  4.802503 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  23\n",
      "Loss Color:  0.010344671 (Train)\n",
      "Loss Category:  4.7901177 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010323504 (Test)\n",
      "Loss Category:  4.8033166 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  24\n",
      "Loss Color:  0.010373281 (Train)\n",
      "Loss Category:  4.790203 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.0103094 (Test)\n",
      "Loss Category:  4.8048506 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  25\n",
      "Loss Color:  0.010362484 (Train)\n",
      "Loss Category:  4.7900224 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010309989 (Test)\n",
      "Loss Category:  4.805348 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  26\n",
      "Loss Color:  0.0103557585 (Train)\n",
      "Loss Category:  4.789806 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010353461 (Test)\n",
      "Loss Category:  4.8060217 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  27\n",
      "Loss Color:  0.010340281 (Train)\n",
      "Loss Category:  4.7899384 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010308437 (Test)\n",
      "Loss Category:  4.806187 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  28\n",
      "Loss Color:  0.010348026 (Train)\n",
      "Loss Category:  4.789609 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010325736 (Test)\n",
      "Loss Category:  4.8070292 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:57<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  29\n",
      "Loss Color:  0.010371546 (Train)\n",
      "Loss Category:  4.789782 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.010354297 (Test)\n",
      "Loss Category:  4.807132 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:56<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  30\n",
      "Loss Color:  0.01034959 (Train)\n",
      "Loss Category:  4.7895756 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Color:  0.01032432 (Test)\n",
      "Loss Category:  4.8080077 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "epochs = 30\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_function_color = tf.keras.losses.MeanSquaredError()\n",
    "loss_function_category = tf.keras.losses.CategoricalCrossentropy()\n",
    "#autoencoder = Autoencoder(optimizer=optimizer, loss_function=loss_function)\n",
    "\n",
    "colorization_model= Colorization_Model(optimizer=optimizer, loss_function_color=loss_function_color, loss_function_category=loss_function_category)\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "save_path = f\"models/{current_time}\"\n",
    "train_log_path = f\"logs/{current_time}/train\"\n",
    "test_log_path = f\"logs/{current_time}/test\"\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_path)\n",
    "training_loop(colorization_model, train_dataset, test_dataset, epochs, train_summary_writer, test_summary_writer, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-25f008fae662c660\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-25f008fae662c660\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be5498235a11125f8b9cbeecb800fcd2f42e8279b58f495bdc82a203ff5bcb8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
